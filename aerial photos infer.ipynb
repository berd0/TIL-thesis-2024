{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:46:30.646544Z",
     "start_time": "2024-07-08T16:46:30.642892Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import convnext_large, ConvNeXt_Large_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from srai.neighbourhoods import H3Neighbourhood\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dc20cb4cd411d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:54:19.151984Z",
     "start_time": "2024-07-08T15:54:19.148461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model architecture (make sure this matches your trained model)\n",
    "class FineTunedConvNeXt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convnext = convnext_large(weights=ConvNeXt_Large_Weights.DEFAULT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.convnext(x)\n",
    "        return features.view(features.size(0), -1)  # Flatten the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc37416885e64d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:54:21.711445Z",
     "start_time": "2024-07-08T15:54:19.152487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FineTunedConvNeXt().to(device)\n",
    "checkpoint_path = r\"D:\\tu delft\\Afstuderen\\Phase 6 Experiments\\checkpoints\\final_model.pth\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Print the number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b28d7cd337b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:54:21.718564Z",
     "start_time": "2024-07-08T15:54:21.712447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset for inference with error handling\n",
    "class RegionDataset(Dataset):\n",
    "    def __init__(self, regions_gdf, image_dir, transform):\n",
    "        self.regions_gdf = regions_gdf\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.missing_regions = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.regions_gdf)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        region_id = self.regions_gdf.index[idx]\n",
    "        image_path = os.path.join(self.image_dir, f\"{region_id}.jpg\")\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            return self.transform(image), region_id\n",
    "        except FileNotFoundError:\n",
    "            self.missing_regions.append(region_id)\n",
    "            return torch.zeros(3, 224, 224), region_id  # Return a blank image tensor\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(model, regions_gdf, image_dir, device, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = RegionDataset(regions_gdf, image_dir, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    embeddings = {}\n",
    "    with torch.no_grad():\n",
    "        for images, region_ids in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            for feature, region_id in zip(features, region_ids):\n",
    "                if not torch.all(images[region_ids.index(region_id)] == 0):\n",
    "                    embeddings[region_id] = feature.cpu().numpy()\n",
    "\n",
    "    return pd.DataFrame.from_dict(embeddings, orient='index'), dataset.missing_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda8b6c113b23c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T15:54:21.722851Z",
     "start_time": "2024-07-08T15:54:21.719566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to perform spatial aggregation for missing regions\n",
    "def spatial_aggregation(missing_regions, embeddings_df, regions_gdf):\n",
    "    neighborhood = H3Neighbourhood(regions_gdf)\n",
    "    for region_id in missing_regions:\n",
    "        neighbors = neighborhood.get_neighbours_at_distance(region_id, 1)\n",
    "        neighbor_embeddings = embeddings_df.loc[embeddings_df.index.isin(neighbors)]\n",
    "        if not neighbor_embeddings.empty:\n",
    "            aggregated_embedding = neighbor_embeddings.mean().values\n",
    "            embeddings_df.loc[region_id] = aggregated_embedding\n",
    "    return embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d3029ac16de57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:00:45.891129Z",
     "start_time": "2024-07-08T15:54:21.723354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your data and generate embeddings\n",
    "regions_gdf = gpd.read_file(\"selected_regions_10.geojson\").set_index(\"region_id\")\n",
    "image_dir = r\"D:\\tu delft\\Afstuderen\\aerial_images_10\"\n",
    "\n",
    "print(\"Generating embeddings for central regions...\")\n",
    "embeddings_df, missing_regions = generate_embeddings(model, regions_gdf, image_dir, device, batch_size=128)\n",
    "\n",
    "print(f\"Number of missing regions: {len(missing_regions)}\")\n",
    "print(\"Performing spatial aggregation for missing regions...\")\n",
    "embeddings_df = spatial_aggregation(missing_regions, embeddings_df, regions_gdf)\n",
    "\n",
    "# Save the embeddings\n",
    "output_dir = r\"D:\\tu delft\\Afstuderen\\Phase 6 Experiments\\embeddings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f\"inferred_embeddings_res_10.csv\")\n",
    "embeddings_df.to_csv(output_file)\n",
    "print(f\"Embeddings saved to {output_file}\")\n",
    "\n",
    "print(\"Inference completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6975f06fc504ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:42:23.924921Z",
     "start_time": "2024-07-08T16:42:23.922039Z"
    }
   },
   "outputs": [],
   "source": [
    "# from Plotting import pca_plot, cluster_plot\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# cluster_plot(embeddings_df, regions_gdf, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e30b8bffa86df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:09.309841Z",
     "start_time": "2024-07-08T16:47:09.305928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define target columns and their properties\n",
    "target_columns = ['afw', 'vrz', 'fys', 'soc', 'onv', 'won']\n",
    "target_names = {\n",
    "    'afw': 'Liveability',\n",
    "    'vrz': 'Amenities',\n",
    "    'fys': 'Physical Environment',\n",
    "    'soc': 'Social Cohesion',\n",
    "    'onv': 'Safety',\n",
    "    'won': 'Housing Stock'\n",
    "}\n",
    "colors = {\n",
    "    'afw': '#808080',  # Dark Grey for Liveability\n",
    "    'vrz': '#FF4500',  # Orange Red for Amenities\n",
    "    'fys': '#32CD32',  # Lime Green for Physical Environment\n",
    "    'soc': '#8A2BE2',  # Blue Violet for Social Cohesion\n",
    "    'onv': '#1E90FF',  # Dodger Blue for Safety\n",
    "    'won': '#FFA500'   # Orange for Housing Stock\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155f974d3c9f7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:49:51.117692Z",
     "start_time": "2024-07-08T16:49:50.128041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare PCA-reduced embeddings\n",
    "X_full = embeddings_df.values\n",
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X_full)\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Perform linear regression for each target column\n",
    "for column in target_columns:\n",
    "    y = regions_gdf[column]\n",
    "\n",
    "    # Remove NaN values\n",
    "    mask = ~(np.isnan(y) | np.isnan(X_pca).any(axis=1))\n",
    "    X_pca_valid = X_pca[mask]\n",
    "    y_valid = y[mask]\n",
    "\n",
    "    if len(y_valid) == 0:\n",
    "        print(f\"Warning: No valid data for {column} after removing NaN values.\")\n",
    "        results[column] = np.nan\n",
    "        continue\n",
    "\n",
    "    # PCA-reduced regression\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca_valid, y_valid, test_size=0.3, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[column] = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fddaaf8bf0d976",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:49:51.486852Z",
     "start_time": "2024-07-08T16:49:51.119194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(target_columns))\n",
    "width = 0.6\n",
    "\n",
    "plt.bar(x, [results[col] for col in target_columns], width,\n",
    "        color=[colors[col] for col in target_columns])\n",
    "\n",
    "plt.xlabel('Leefbaarometer Scores', fontsize=12)\n",
    "plt.ylabel('R² Score', fontsize=12)\n",
    "plt.title('Performance of PCA-reduced (30) Embeddings', fontsize=14)\n",
    "plt.xticks(x, [target_names[col] for col in target_columns], rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "output_dir = r\"D:\\tu delft\\Afstuderen\\Phase 6 Experiments\\embeddings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(output_dir, 'pca_reduced_performance.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"PCA-reduced embedding analysis completed and plot saved.\")\n",
    "print(\"R² scores for each Leefbaarometer score:\")\n",
    "for col in target_columns:\n",
    "    print(f\"{target_names[col]}: {results[col]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de9d427c3fee25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
