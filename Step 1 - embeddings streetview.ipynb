{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:30.622298Z",
     "start_time": "2024-07-03T16:43:30.619161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import convnext_large, ConvNeXt_Large_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067a9e95c5aabe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:30.628575Z",
     "start_time": "2024-07-03T16:43:30.624300Z"
    }
   },
   "outputs": [],
   "source": [
    "class StreetViewDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        images = []\n",
    "        region_id = row['h3_9']\n",
    "        for col in ['path_side_a', 'path_front', 'path_side_b', 'path_back']:\n",
    "            img_path = self.root_dir / row[col]\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        if not images:\n",
    "            return None, None\n",
    "        images_tensor = torch.stack(images)\n",
    "        return images_tensor, region_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd75807729c90d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:47.313726Z",
     "start_time": "2024-07-03T16:43:30.629576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Prepare regions\n",
    "regions_buffered_gdf = gpd.read_file(\"selected_regions_buffered_9.geojson\")\n",
    "regions_gdf = gpd.read_file(\"selected_regions_9.geojson\")\n",
    "regions_buffered_gdf.set_index('region_id', inplace=True)\n",
    "regions_gdf.set_index('region_id', inplace=True)\n",
    "\n",
    "# import panoids.geojson\n",
    "path = \"D://tu delft//Afstuderen//imagesummary//data//South_Holland_NL\"\n",
    "panoids_gdf = gpd.read_file(path + \"//panoids//panoids.geojson\")\n",
    "image_root_dir = \"D://tu delft//Afstuderen//imagesummary//data//South_Holland_NL//imagedb//\"\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = convnext_large(weights=ConvNeXt_Large_Weights.DEFAULT)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482f0d4b357d0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:47.318803Z",
     "start_time": "2024-07-03T16:43:47.314227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Initialize the dataset and dataloader\n",
    "dataset = StreetViewDataset(panoids_gdf, image_root_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db933f1d17cb21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T16:43:47.326395Z",
     "start_time": "2024-07-03T16:43:47.320305Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_embeddings(dataloader, model, device):\n",
    "    mean_embeddings_list = []\n",
    "    max_embeddings_list = []\n",
    "    region_ids_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, region_ids in tqdm(dataloader):\n",
    "            if images is None:\n",
    "                continue\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            batch_mean_embeddings = []\n",
    "            batch_max_embeddings = []\n",
    "            for i in range(images.shape[0]):\n",
    "                item_images = images[i]\n",
    "\n",
    "                mean_aggregated_images = torch.mean(item_images, dim=0).unsqueeze(0)\n",
    "                max_aggregated_images = torch.max(item_images, dim=0)[0].unsqueeze(0)\n",
    "\n",
    "                mean_output = model(mean_aggregated_images)\n",
    "                max_output = model(max_aggregated_images)\n",
    "\n",
    "                batch_mean_embeddings.append(mean_output.cpu().numpy().flatten())\n",
    "                batch_max_embeddings.append(max_output.cpu().numpy().flatten())\n",
    "\n",
    "            mean_embeddings_list.extend(batch_mean_embeddings)\n",
    "            max_embeddings_list.extend(batch_max_embeddings)\n",
    "            if isinstance(region_ids, torch.Tensor):\n",
    "                region_ids_list.extend(region_ids.cpu().numpy())\n",
    "            else:\n",
    "                region_ids_list.extend(region_ids)\n",
    "\n",
    "    mean_embeddings_df = pd.DataFrame(mean_embeddings_list)\n",
    "    max_embeddings_df = pd.DataFrame(max_embeddings_list)\n",
    "\n",
    "    mean_embeddings_df['region_id'] = region_ids_list\n",
    "    max_embeddings_df['region_id'] = region_ids_list\n",
    "\n",
    "    mean_embeddings_df.set_index('region_id', inplace=True)\n",
    "    max_embeddings_df.set_index('region_id', inplace=True)\n",
    "\n",
    "    mean_embeddings_df.columns = [f'emb_mean_{i}' for i in range(mean_embeddings_df.shape[1])]\n",
    "    max_embeddings_df.columns = [f'emb_max_{i}' for i in range(max_embeddings_df.shape[1])]\n",
    "\n",
    "    return mean_embeddings_df, max_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43568d4930e759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T17:08:54.410371Z",
     "start_time": "2024-07-03T16:43:47.327397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract embeddings, applying max and mean aggregation to panoids\n",
    "mean_embeddings_df, max_embeddings_df = extract_embeddings(dataloader, model, device)\n",
    "\n",
    "# Check if the DataFrames are not None and print their shapes\n",
    "if mean_embeddings_df is not None and max_embeddings_df is not None:\n",
    "    print(f\"Mean Embeddings DataFrame shape: {mean_embeddings_df.shape}\")\n",
    "    print(f\"Max Embeddings DataFrame shape: {max_embeddings_df.shape}\")\n",
    "else:\n",
    "    print(\"Error: Embeddings DataFrames are None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef60cfe5890227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T17:08:54.422688Z",
     "start_time": "2024-07-03T17:08:54.411378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrames\n",
    "print(\"Mean Embeddings:\")\n",
    "print(mean_embeddings_df.head())\n",
    "print(\"Max Embeddings:\")\n",
    "print(max_embeddings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b9972e13942d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T17:09:37.673874Z",
     "start_time": "2024-07-03T17:08:54.423693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "mean_embeddings_df.to_csv('embeddings_streetview_mean_9.csv')\n",
    "max_embeddings_df.to_csv('embeddings_streetview_max_9_convnext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefbf2014add583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T17:12:00.842074Z",
     "start_time": "2024-07-03T17:11:52.059081Z"
    }
   },
   "outputs": [],
   "source": [
    "# PCA Plot (Optional)\n",
    "from Plotting import pca_plot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pca_plot(mean_embeddings_df, regions_buffered_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcaf5d4a6b04ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T17:13:27.532333Z",
     "start_time": "2024-07-03T17:13:19.846808Z"
    }
   },
   "outputs": [],
   "source": [
    "pca_plot(max_embeddings_df, regions_buffered_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93d2e617ec611b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
