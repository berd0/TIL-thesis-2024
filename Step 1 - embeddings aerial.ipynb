{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4602eb83995f57",
   "metadata": {},
   "source": [
    "Uses ConvNeXT instead of ResNet50 for the embeddings of the aerial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:44:57.973388Z",
     "start_time": "2024-07-03T14:44:46.791608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import convnext_large, ConvNeXt_Large_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd0d7aa8a112d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:44:57.978872Z",
     "start_time": "2024-07-03T14:44:57.974890Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegionsDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.missing_images = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = Path(self.root_dir) / f\"{self.dataframe.index[idx]}.jpg\"\n",
    "        if not img_name.exists():\n",
    "            self.missing_images.append(self.dataframe.index[idx])\n",
    "            return None  # Skip missing images\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c100435f5c1a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:45:06.314989Z",
     "start_time": "2024-07-03T14:44:57.979873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Prepare regions\n",
    "regions_buffered_gdf = gpd.read_file(\"selected_regions_buffered_9.geojson\")\n",
    "regions_buffered_gdf = regions_buffered_gdf.to_crs(epsg=28992)\n",
    "regions_buffered_gdf.set_index('region_id', inplace=True)\n",
    "bbox = regions_buffered_gdf.geometry.bounds\n",
    "regions_buffered_gdf['minx'] = bbox['minx']\n",
    "regions_buffered_gdf['miny'] = bbox['miny']\n",
    "regions_buffered_gdf['maxx'] = bbox['maxx']\n",
    "regions_buffered_gdf['maxy'] = bbox['maxy']\n",
    "\n",
    "# Verify if regions_buffered_gdf index is contained within the image folder\n",
    "assert regions_buffered_gdf.index.isin([f.stem for f in Path(\"../images\").glob(\"*.jpg\")]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c0536017e8518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:45:16.541313Z",
     "start_time": "2024-07-03T14:45:06.315990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Load the Pretrained ConvNeXt Large Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device {device}')\n",
    "model = convnext_large(weights=ConvNeXt_Large_Weights.DEFAULT)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573b82af9ec0e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:51:44.014562Z",
     "start_time": "2024-07-03T14:45:16.542815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Infer Embeddings for Each Region\n",
    "# Initialize the dataset and dataloader\n",
    "dataset = RegionsDataset(dataframe=regions_buffered_gdf, root_dir=\"../images\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Extract embeddings\n",
    "embeddings = []\n",
    "missing_images_info = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(dataloader):\n",
    "        if images is None:  # Ensure there are no None values\n",
    "            continue\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        embeddings.extend(outputs.cpu().numpy())  # Collect embeddings\n",
    "\n",
    "# Log missing images after processing\n",
    "if dataset.missing_images:\n",
    "    missing_images_info = regions_buffered_gdf.loc[dataset.missing_images]\n",
    "\n",
    "# Flatten the embeddings and prepare for DataFrame\n",
    "flattened_embeddings = np.vstack(embeddings).reshape(len(embeddings), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a71af48a62b66b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:51:46.344455Z",
     "start_time": "2024-07-03T14:51:44.015568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Create the DataFrame\n",
    "aerial_embeddings_df = pd.DataFrame(flattened_embeddings, index=regions_buffered_gdf.index)\n",
    "aerial_embeddings_df.columns = [f\"emb_{i}\" for i in range(flattened_embeddings.shape[1])]\n",
    "\n",
    "# Apply Principal Component Analysis to reduce dimensionality\n",
    "pca = PCA(n_components=512)\n",
    "reduced_embeddings = pca.fit_transform(aerial_embeddings_df)\n",
    "\n",
    "# Create a new DataFrame for the reduced embeddings\n",
    "reduced_embeddings_df = pd.DataFrame(reduced_embeddings, index=aerial_embeddings_df.index)\n",
    "reduced_embeddings_df.columns = [f'PCA_{i}' for i in range(512)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0032bc3fba1675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:52:18.664508Z",
     "start_time": "2024-07-03T14:51:46.345457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Export the embeddings to a CSV file\n",
    "aerial_embeddings_df.to_csv('embeddings_aerial_9_convnext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bcc558320fdbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:45:38.910499Z",
     "start_time": "2024-09-24T09:45:38.907692Z"
    }
   },
   "outputs": [],
   "source": [
    "# from Plotting import pca_plot, cluster_plot\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# cluster_plot(reduced_embeddings_df, regions_buffered_gdf, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7942d6c9a444f2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:54:58.120934Z",
     "start_time": "2024-07-03T14:54:51.971108Z"
    }
   },
   "outputs": [],
   "source": [
    "# import embeddings aerial resnet50\n",
    "aerial_embeddings_resnet50_df = pd.read_csv('embeddings_aerial_9_resnet50.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385bbba379c8f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:58:39.927873Z",
     "start_time": "2024-07-03T14:57:47.643127Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_plot(aerial_embeddings_resnet50_df, regions_buffered_gdf, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629215d61698f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
